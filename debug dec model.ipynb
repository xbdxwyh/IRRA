{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123ed2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import os.path as op\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from datasets import build_dataloader\n",
    "from processor.processor import do_train\n",
    "from utils.checkpoint import Checkpointer\n",
    "from utils.iotools import save_train_configs\n",
    "from utils.logger import setup_logger\n",
    "from solver import build_optimizer, build_lr_scheduler\n",
    "from model import build_model\n",
    "from utils.metrics import Evaluator\n",
    "from utils.options import get_args\n",
    "from utils.comm import get_rank, synchronize\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2313473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be3d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def get_temp_args():\n",
    "    parser = argparse.ArgumentParser(description=\"IRRA Args\")\n",
    "    ######################## general settings ########################\n",
    "    parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "    parser.add_argument(\"--name\", default=\"baseline\", help=\"experiment name to save\")\n",
    "    parser.add_argument(\"--output_dir\", default=\"logs\")\n",
    "    parser.add_argument(\"--log_period\", default=100)\n",
    "    parser.add_argument(\"--eval_period\", default=1)\n",
    "    parser.add_argument(\"--val_dataset\", default=\"test\") # use val set when evaluate, if test use test set\n",
    "    parser.add_argument(\"--resume\", default=False, action='store_true')\n",
    "    parser.add_argument(\"--resume_ckpt_file\", default=\"\", help='resume from ...')\n",
    "\n",
    "    ######################## model general settings ########################\n",
    "    parser.add_argument(\"--pretrain_choice\", default='ViT-B/16') # whether use pretrained model\n",
    "    parser.add_argument(\"--temperature\", type=float, default=0.02, help=\"initial temperature value, if 0, don't use temperature\")\n",
    "    parser.add_argument(\"--img_aug\", default=False, action='store_true')\n",
    "\n",
    "    ## cross modal transfomer setting\n",
    "    parser.add_argument(\"--cmt_depth\", type=int, default=4, help=\"cross modal transformer self attn layers\")\n",
    "    parser.add_argument(\"--masked_token_rate\", type=float, default=0.8, help=\"masked token rate for mlm task\")\n",
    "    parser.add_argument(\"--masked_token_unchanged_rate\", type=float, default=0.1, help=\"masked token unchanged rate\")\n",
    "    parser.add_argument(\"--lr_factor\", type=float, default=5.0, help=\"lr factor for random init self implement module\")\n",
    "    parser.add_argument(\"--MLM\", default=False, action='store_true', help=\"whether to use Mask Language Modeling dataset\")\n",
    "\n",
    "    ######################## loss settings ########################\n",
    "    parser.add_argument(\"--loss_names\", default='sdm+id+mlm', help=\"which loss to use ['mlm', 'cmpm', 'id', 'itc', 'sdm']\")\n",
    "    parser.add_argument(\"--mlm_loss_weight\", type=float, default=1.0, help=\"mlm loss weight\")\n",
    "    parser.add_argument(\"--id_loss_weight\", type=float, default=1.0, help=\"id loss weight\")\n",
    "    \n",
    "    ######################## vison trainsformer settings ########################\n",
    "    parser.add_argument(\"--img_size\", type=tuple, default=(384, 128))\n",
    "    parser.add_argument(\"--stride_size\", type=int, default=16)\n",
    "\n",
    "    ######################## text transformer settings ########################\n",
    "    parser.add_argument(\"--text_length\", type=int, default=77)\n",
    "    parser.add_argument(\"--vocab_size\", type=int, default=49408)\n",
    "\n",
    "    ######################## solver ########################\n",
    "    parser.add_argument(\"--optimizer\", type=str, default=\"Adam\", help=\"[SGD, Adam, Adamw]\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-5)\n",
    "    parser.add_argument(\"--bias_lr_factor\", type=float, default=2.)\n",
    "    parser.add_argument(\"--momentum\", type=float, default=0.9)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=4e-5)\n",
    "    parser.add_argument(\"--weight_decay_bias\", type=float, default=0.)\n",
    "    parser.add_argument(\"--alpha\", type=float, default=0.9)\n",
    "    parser.add_argument(\"--beta\", type=float, default=0.999)\n",
    "    \n",
    "    ######################## scheduler ########################\n",
    "    parser.add_argument(\"--num_epoch\", type=int, default=60)\n",
    "    parser.add_argument(\"--milestones\", type=int, nargs='+', default=(20, 50))\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--warmup_factor\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--warmup_epochs\", type=int, default=5)\n",
    "    parser.add_argument(\"--warmup_method\", type=str, default=\"linear\")\n",
    "    parser.add_argument(\"--lrscheduler\", type=str, default=\"cosine\")\n",
    "    parser.add_argument(\"--target_lr\", type=float, default=0)\n",
    "    parser.add_argument(\"--power\", type=float, default=0.9)\n",
    "\n",
    "    ######################## dataset ########################\n",
    "    parser.add_argument(\"--dataset_name\", default=\"CUHK-PEDES\", help=\"[CUHK-PEDES, ICFG-PEDES, RSTPReid]\")\n",
    "    parser.add_argument(\"--sampler\", default=\"random\", help=\"choose sampler from [idtentity, random]\")\n",
    "    parser.add_argument(\"--num_instance\", type=int, default=4)\n",
    "    parser.add_argument(\"--root_dir\", default=\"./data\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--test_batch_size\", type=int, default=512)\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=8)\n",
    "    parser.add_argument(\"--test\", dest='training', default=True, action='store_false')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64639e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_temp_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d13a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=[\n",
    "    \"--name\",\"irra\",\n",
    "    \"--img_aug\",\"--MLM\",\n",
    "    \"--batch_size\",\"6\",\n",
    "    \"--loss_names\",\"itc+proj\",\n",
    "    \"--dataset_name\",\"AGTBPR\",\n",
    "    \"--root_dir\",r\"F:\\Datasets\\AG-ReID.v1\",\n",
    "    \"--num_epoch\",\"60\",\n",
    "    \"--cmt_depth\",\"1\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a85c329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(local_rank=0, name='irra', output_dir='logs', log_period=100, eval_period=1, val_dataset='test', resume=False, resume_ckpt_file='', pretrain_choice='ViT-B/16', temperature=0.02, img_aug=True, cmt_depth=1, masked_token_rate=0.8, masked_token_unchanged_rate=0.1, lr_factor=5.0, MLM=True, loss_names='itc+proj', mlm_loss_weight=1.0, id_loss_weight=1.0, img_size=(384, 128), stride_size=16, text_length=77, vocab_size=49408, optimizer='Adam', lr=1e-05, bias_lr_factor=2.0, momentum=0.9, weight_decay=4e-05, weight_decay_bias=0.0, alpha=0.9, beta=0.999, num_epoch=60, milestones=(20, 50), gamma=0.1, warmup_factor=0.1, warmup_epochs=5, warmup_method='linear', lrscheduler='cosine', target_lr=0, power=0.9, dataset_name='AGTBPR', sampler='random', num_instance=4, root_dir='F:\\\\Datasets\\\\AG-ReID.v1', batch_size=6, test_batch_size=512, num_workers=8, training=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904d606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+----------+\n",
      "| subset | ids | images | captions |\n",
      "+--------+-----+--------+----------+\n",
      "| train  | 199 |  8154  |   8154   |\n",
      "|  test  | 189 |  1149  |   1149   |\n",
      "|  val   | 189 |  7204  |   7204   |\n",
      "+--------+-----+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_img_loader, val_txt_loader, num_classes = build_dataloader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8646469",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    batch = {k: v.to(torch.device(\"cuda:0\")) for k, v in batch.items()}\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db35fd",
   "metadata": {},
   "source": [
    "# test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27361a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.img_size = (args.img_size[0]+args.stride_size*2,args.img_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "602d96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.token_num = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd9f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model with ['itc', 'proj'] tasks\n",
      "Resized position embedding from size:torch.Size([1, 197, 768]) to size: torch.Size([1, 209, 768]) with height:26 width: 8\n"
     ]
    }
   ],
   "source": [
    "model = build_model(args, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca5f0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "272fb216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total params: 179M'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Total params: %2.fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46146517",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81e4f744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': tensor(0.0200),\n",
       " 'loss_proj': tensor(1.9277, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " 'itc_loss': tensor(1.6424, device='cuda:0', grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b84773d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1359/1359 [03:04<00:00,  7.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm.tqdm(train_loader):\n",
    "    batch = {k: v.to(torch.device(\"cuda:0\")) for k, v in batch.items()}\n",
    "    ret = model(batch)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beedc31c",
   "metadata": {},
   "source": [
    "# Debug model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11c9d286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.proj_prefix.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7833c022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (resblocks): Sequential(\n",
       "    (0): ResidualAttentionBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (gelu): QuickGELU()\n",
       "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cross_modal_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1bbc4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = batch['images']\n",
    "caption_ids = batch['caption_ids']\n",
    "image_feats, text_feats = model.base_model(images.to(torch.float16), caption_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2e52ef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4673, -0.2153,  0.1763,  ..., -0.1285,  0.2556,  0.0911],\n",
       "         [-0.2076, -0.4395, -0.1622,  ..., -0.1357, -0.4082, -0.0923],\n",
       "         [-0.1691, -0.2532,  0.1851,  ...,  0.1747,  0.0487, -0.1838],\n",
       "         ...,\n",
       "         [-0.2209, -0.1714,  0.1213,  ...,  0.0792, -0.1569,  0.0273],\n",
       "         [ 0.0170, -0.1510, -0.0058,  ...,  0.0731, -0.0576, -0.2205],\n",
       "         [-0.2681, -0.4751,  0.0470,  ..., -0.0914, -0.0970, -0.1152]],\n",
       "\n",
       "        [[ 0.3862, -0.2991, -0.2688,  ..., -0.0126,  0.3752,  0.1027],\n",
       "         [-0.0489,  0.1192, -0.0728,  ...,  0.3779,  0.2159, -0.2103],\n",
       "         [-0.1732,  0.0795,  0.0630,  ...,  0.0494,  0.0748, -0.2546],\n",
       "         ...,\n",
       "         [-0.3430,  0.0327, -0.3711,  ...,  0.1998, -0.3416,  0.0274],\n",
       "         [-0.2734, -0.0792, -0.1304,  ...,  0.1578, -0.2462, -0.0635],\n",
       "         [-0.2852, -0.2664, -0.1409,  ...,  0.1362, -0.1469,  0.0829]],\n",
       "\n",
       "        [[ 0.3259,  0.0110, -0.0614,  ..., -0.1625,  0.3955,  0.2661],\n",
       "         [-0.6494, -0.2656, -0.1009,  ...,  0.0961, -0.0079, -0.1710],\n",
       "         [-0.0359,  0.3682,  0.4773,  ..., -0.1827, -0.0552, -0.0100],\n",
       "         ...,\n",
       "         [ 0.0378,  0.0916, -0.1141,  ...,  0.1565, -0.0995, -0.3208],\n",
       "         [-0.4104, -0.2693, -0.3337,  ...,  0.0541, -0.1683, -0.0034],\n",
       "         [-0.7295, -0.4231, -0.2405,  ...,  0.1401, -0.0681,  0.0554]],\n",
       "\n",
       "        [[ 0.3689, -0.2671, -0.3374,  ..., -0.2097,  0.4517,  0.3394],\n",
       "         [ 0.0126,  0.1401, -0.2815,  ...,  0.0679, -0.2170, -0.0217],\n",
       "         [ 0.0590,  0.3743, -0.1059,  ...,  0.4773,  0.1131,  0.0406],\n",
       "         ...,\n",
       "         [-0.0964,  0.1460,  0.4941,  ...,  0.1339,  0.0674, -0.1584],\n",
       "         [-0.2070, -0.0183, -0.2422,  ...,  0.0461, -0.0891,  0.0895],\n",
       "         [-0.2469, -0.5264, -0.0470,  ..., -0.1249, -0.0892,  0.0610]],\n",
       "\n",
       "        [[ 0.4434,  0.2866,  0.1466,  ...,  0.0507,  0.4380,  0.2220],\n",
       "         [-0.0607, -0.2839, -0.3215,  ..., -0.0930, -0.2339,  0.1573],\n",
       "         [-0.2043, -0.2343, -0.2434,  ...,  0.1021, -0.1598,  0.0617],\n",
       "         ...,\n",
       "         [-0.2169,  0.1973,  0.0892,  ..., -0.0739,  0.0049,  0.2246],\n",
       "         [ 0.0893,  0.0948,  0.1752,  ...,  0.0317,  0.2091, -0.2065],\n",
       "         [-0.4731, -0.3455,  0.0873,  ..., -0.0942, -0.0768, -0.0257]],\n",
       "\n",
       "        [[ 0.4998, -0.4812, -0.3145,  ..., -0.2257,  0.2947,  0.1760],\n",
       "         [ 0.1785, -0.1909,  0.1069,  ..., -0.1975,  0.2849,  0.0723],\n",
       "         [ 0.1511, -0.1594, -0.1609,  ..., -0.1351,  0.4644, -0.0843],\n",
       "         ...,\n",
       "         [-0.3298, -0.4822, -0.2805,  ..., -0.0638, -0.0674,  0.0952],\n",
       "         [-0.0073, -0.2340, -0.3613,  ..., -0.2400,  0.0159, -0.2355],\n",
       "         [-0.3872, -0.6484, -0.3403,  ..., -0.2644, -0.0975,  0.0221]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dbacf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_scale = model.logit_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e60c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = image_feats.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86e26cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 16, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.proj_prefix.unsqueeze(0).repeat(bs,1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc4598be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.cross_former(model.proj_prefix.unsqueeze(0).repeat(bs,1,1).to(torch.float16), image_feats, image_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08156198",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_casual = model.proj_dec(\n",
    "    inputs_embeds = x,\n",
    "    is_casual=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a09d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_attn = model.proj_dec(\n",
    "    inputs_embeds = x,\n",
    "    is_casual=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7209558",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pair = batch['pair_img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92f16196",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pair_feats = model.base_model.encode_image(y_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83d34b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7297e-01,  4.2297e-02,  2.8534e-02,  ...,  1.3220e-01,\n",
       "          -2.5520e-03,  4.9561e-01],\n",
       "         [-7.7979e-01,  5.8105e-02, -2.1229e-03,  ...,  1.4075e-01,\n",
       "          -1.6650e-01,  4.7943e-02],\n",
       "         [-4.1553e-01,  1.3245e-01, -3.6316e-02,  ..., -5.8899e-02,\n",
       "           2.2614e-02,  8.0750e-02],\n",
       "         ...,\n",
       "         [-1.2769e-01,  3.2251e-01,  4.8950e-01,  ...,  2.3340e-01,\n",
       "          -2.2598e-02,  3.8379e-01],\n",
       "         [-3.2666e-01,  2.5928e-01,  1.9690e-01,  ...,  2.0166e-01,\n",
       "           1.2421e-01,  3.1445e-01],\n",
       "         [-5.1465e-01, -1.6382e-01,  3.3752e-02,  ...,  7.4341e-02,\n",
       "          -1.2671e-01,  4.0710e-02]],\n",
       "\n",
       "        [[ 6.8555e-01, -4.9927e-01, -1.7200e-01,  ...,  2.3633e-01,\n",
       "           2.9858e-01,  2.8516e-01],\n",
       "         [ 1.2427e-01,  6.7406e-03, -6.8909e-02,  ...,  3.9697e-01,\n",
       "          -3.3691e-01, -5.1178e-02],\n",
       "         [ 1.8713e-01,  9.4971e-02, -4.7925e-01,  ...,  3.2422e-01,\n",
       "           7.3730e-02, -6.9397e-02],\n",
       "         ...,\n",
       "         [ 7.0251e-02, -2.1094e-01, -8.0750e-02,  ...,  2.1497e-01,\n",
       "           2.7905e-01,  1.9519e-01],\n",
       "         [-3.4814e-01, -2.9346e-01, -1.6876e-02,  ...,  2.0215e-01,\n",
       "          -1.0394e-01,  1.6895e-01],\n",
       "         [-3.9380e-01, -6.2305e-01, -1.6309e-01,  ..., -7.9041e-02,\n",
       "          -9.7351e-02,  6.2683e-02]],\n",
       "\n",
       "        [[-1.6614e-01, -3.8647e-01, -5.9229e-01,  ...,  8.8074e-02,\n",
       "           3.4961e-01,  2.3889e-01],\n",
       "         [-2.0215e-01, -1.7444e-01,  8.8684e-02,  ...,  1.8689e-01,\n",
       "          -3.5553e-03,  1.0406e-01],\n",
       "         [-4.3286e-01,  1.1096e-01,  4.3311e-01,  ...,  1.2415e-01,\n",
       "          -1.9336e-01, -2.2290e-01],\n",
       "         ...,\n",
       "         [-8.0371e-01,  2.9956e-01, -1.1133e-01,  ...,  1.6663e-01,\n",
       "          -3.9795e-01, -7.8735e-02],\n",
       "         [-3.6572e-01, -4.2358e-01, -2.9443e-01,  ..., -2.9712e-01,\n",
       "          -4.3677e-01,  1.3416e-01],\n",
       "         [-3.6621e-01, -5.9082e-01, -1.9958e-01,  ..., -4.4586e-02,\n",
       "          -2.9761e-01,  2.3651e-02]],\n",
       "\n",
       "        [[-2.3972e-02, -4.8901e-01, -1.3123e-02,  ..., -1.4816e-02,\n",
       "           2.6270e-01,  1.0852e-01],\n",
       "         [ 1.8652e-01, -3.8916e-01,  2.0496e-01,  ...,  5.5518e-01,\n",
       "          -2.5708e-01,  6.3232e-02],\n",
       "         [ 4.0259e-01, -3.1494e-01,  2.0471e-01,  ...,  6.0791e-01,\n",
       "           2.0630e-02,  2.2314e-01],\n",
       "         ...,\n",
       "         [-1.3660e-01,  3.5461e-02, -2.1423e-01,  ...,  3.7012e-01,\n",
       "           6.0730e-03, -2.6221e-01],\n",
       "         [-2.4670e-01, -2.2168e-01, -2.6392e-01,  ...,  4.4775e-01,\n",
       "           1.0394e-01, -1.3684e-01],\n",
       "         [-1.2988e-01, -4.6112e-02, -3.5736e-02,  ...,  5.3467e-01,\n",
       "           1.0382e-01, -2.8296e-01]],\n",
       "\n",
       "        [[ 1.3379e-01, -2.0593e-01, -3.9331e-01,  ..., -6.4453e-02,\n",
       "           3.3374e-01,  3.0322e-01],\n",
       "         [-2.5317e-01,  5.1270e-01,  1.2927e-01,  ...,  4.6143e-02,\n",
       "           3.3569e-01,  8.2153e-02],\n",
       "         [-3.5767e-01,  4.8462e-01,  9.6313e-02,  ..., -3.7079e-02,\n",
       "           5.0098e-01, -2.3026e-02],\n",
       "         ...,\n",
       "         [-3.8452e-01,  1.6748e-01, -2.7246e-01,  ..., -1.5297e-02,\n",
       "          -2.6685e-01,  2.6709e-01],\n",
       "         [-1.9336e-01,  7.4244e-04, -3.2617e-01,  ...,  4.6631e-02,\n",
       "          -3.7476e-01, -1.0431e-01],\n",
       "         [-5.6396e-01, -1.3110e-01, -1.2866e-01,  ..., -7.2388e-02,\n",
       "          -3.3789e-01,  2.1118e-01]],\n",
       "\n",
       "        [[ 3.4033e-01, -1.8701e-01, -1.7188e-01,  ...,  1.1902e-01,\n",
       "           3.6353e-01,  2.6294e-01],\n",
       "         [-1.8323e-01, -4.3481e-01, -7.6111e-02,  ...,  3.7781e-02,\n",
       "          -3.3081e-01,  2.0483e-01],\n",
       "         [-1.1493e-01, -5.7959e-01, -1.0773e-01,  ...,  2.3938e-01,\n",
       "          -3.2715e-01,  1.4539e-01],\n",
       "         ...,\n",
       "         [ 1.6833e-01,  1.6431e-01, -1.4209e-01,  ...,  4.1479e-01,\n",
       "          -9.1858e-02, -1.3806e-01],\n",
       "         [ 3.3228e-01, -3.8818e-01,  3.0347e-01,  ...,  3.1470e-01,\n",
       "          -1.4844e-01, -1.5576e-01],\n",
       "         [-2.1741e-01, -2.7417e-01,  2.5415e-01,  ...,  1.7371e-01,\n",
       "          -1.9684e-02,  1.6748e-01]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pair_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5439d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_y_feats = y_pair_feats[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0343d429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 512])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_y_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87ce9519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 192, 512])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pair_feats[:,1:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9f1ac2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 512])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_y_feats.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7495e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_tkn = torch.nn.functional.cosine_similarity(i_y_feats.unsqueeze(1),y_pair_feats[:,1:,:],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53ada4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vlu, idx = torch.sort(sim_tkn,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c451ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4136, 0.4229, 0.4329,  ..., 0.6919, 0.7075, 0.7241],\n",
       "        [0.3496, 0.3809, 0.3845,  ..., 0.6587, 0.6899, 0.7080],\n",
       "        [0.3452, 0.3728, 0.3779,  ..., 0.6069, 0.6235, 0.6641],\n",
       "        [0.3972, 0.4104, 0.4126,  ..., 0.6729, 0.6787, 0.7007],\n",
       "        [0.3535, 0.3582, 0.3669,  ..., 0.5757, 0.5781, 0.5820],\n",
       "        [0.3777, 0.3828, 0.4294,  ..., 0.7197, 0.7251, 0.7334]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<SortBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67321b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[164, 147, 122,  ...,   3, 176,  79],\n",
       "        [ 33,  30,  80,  ..., 126, 169, 109],\n",
       "        [116,  45,  43,  ..., 185, 159,  94],\n",
       "        [ 75,  77,  78,  ..., 144, 116, 105],\n",
       "        [ 34, 124,  75,  ..., 154, 155, 152],\n",
       "        [126, 155, 157,  ...,  30,  86,  78]], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d67fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_idx = idx[:,-model.proj_token_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c69ebf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(bs).unsqueeze(0).reshape(-1,1).repeat(1,model.proj_token_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "03581dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 16])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ecc3eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "73aa7e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([184, 136, 145, 151, 117, 128, 192, 168, 160,  16, 144, 178, 146,   4,\n",
       "        177,  80,  19, 122, 151, 129, 128, 143, 104, 119,  92,  96, 105, 184,\n",
       "        112, 127, 170, 110, 176, 152, 185,  80,  33, 144, 103, 188,  87,  77,\n",
       "         88,  71, 120, 186, 160,  95, 136,  31, 100,  74, 155,   8, 107,  99,\n",
       "        108, 110, 119, 132,  15, 145, 117, 106, 187, 110, 186, 188, 138, 146,\n",
       "        190, 130, 164, 106, 145,  22, 128, 155, 156, 153,  46,  80,  77,  83,\n",
       "         88,  89,  11,  30,  82, 154,  90,  84, 169,  31,  87,  79],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_idx.reshape(-1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a5a40e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gt = y_pair_feats[x.reshape(-1),y_idx.reshape(-1)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6662d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_x = ((x_casual[0]+x_attn[0])*0.5).reshape(bs*model.proj_token_num,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "037feadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8516, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.l1_loss(dec_x,y_gt) + torch.nn.functional.mse_loss(dec_x,y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2ef5a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.randn(4,64) for i in range(10)],dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef3a9f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 640])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.randn(4,64) for i in range(10)],dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc057b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
