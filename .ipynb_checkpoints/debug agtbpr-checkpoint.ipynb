{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123ed2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import os.path as op\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from datasets import build_dataloader\n",
    "from processor.processor import do_train\n",
    "from utils.checkpoint import Checkpointer\n",
    "from utils.iotools import save_train_configs\n",
    "from utils.logger import setup_logger\n",
    "from solver import build_optimizer, build_lr_scheduler\n",
    "from model import build_model\n",
    "from utils.metrics import Evaluator\n",
    "from utils.options import get_args\n",
    "from utils.comm import get_rank, synchronize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2313473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be3d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def get_temp_args():\n",
    "    parser = argparse.ArgumentParser(description=\"IRRA Args\")\n",
    "    ######################## general settings ########################\n",
    "    parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "    parser.add_argument(\"--name\", default=\"baseline\", help=\"experiment name to save\")\n",
    "    parser.add_argument(\"--output_dir\", default=\"logs\")\n",
    "    parser.add_argument(\"--log_period\", default=100)\n",
    "    parser.add_argument(\"--eval_period\", default=1)\n",
    "    parser.add_argument(\"--val_dataset\", default=\"test\") # use val set when evaluate, if test use test set\n",
    "    parser.add_argument(\"--resume\", default=False, action='store_true')\n",
    "    parser.add_argument(\"--resume_ckpt_file\", default=\"\", help='resume from ...')\n",
    "\n",
    "    ######################## model general settings ########################\n",
    "    parser.add_argument(\"--pretrain_choice\", default='ViT-B/16') # whether use pretrained model\n",
    "    parser.add_argument(\"--temperature\", type=float, default=0.02, help=\"initial temperature value, if 0, don't use temperature\")\n",
    "    parser.add_argument(\"--img_aug\", default=False, action='store_true')\n",
    "\n",
    "    ## cross modal transfomer setting\n",
    "    parser.add_argument(\"--cmt_depth\", type=int, default=4, help=\"cross modal transformer self attn layers\")\n",
    "    parser.add_argument(\"--masked_token_rate\", type=float, default=0.8, help=\"masked token rate for mlm task\")\n",
    "    parser.add_argument(\"--masked_token_unchanged_rate\", type=float, default=0.1, help=\"masked token unchanged rate\")\n",
    "    parser.add_argument(\"--lr_factor\", type=float, default=5.0, help=\"lr factor for random init self implement module\")\n",
    "    parser.add_argument(\"--MLM\", default=False, action='store_true', help=\"whether to use Mask Language Modeling dataset\")\n",
    "\n",
    "    ######################## loss settings ########################\n",
    "    parser.add_argument(\"--loss_names\", default='sdm+id+mlm', help=\"which loss to use ['mlm', 'cmpm', 'id', 'itc', 'sdm']\")\n",
    "    parser.add_argument(\"--mlm_loss_weight\", type=float, default=1.0, help=\"mlm loss weight\")\n",
    "    parser.add_argument(\"--id_loss_weight\", type=float, default=1.0, help=\"id loss weight\")\n",
    "    \n",
    "    ######################## vison trainsformer settings ########################\n",
    "    parser.add_argument(\"--img_size\", type=tuple, default=(384, 128))\n",
    "    parser.add_argument(\"--stride_size\", type=int, default=16)\n",
    "\n",
    "    ######################## text transformer settings ########################\n",
    "    parser.add_argument(\"--text_length\", type=int, default=77)\n",
    "    parser.add_argument(\"--vocab_size\", type=int, default=49408)\n",
    "\n",
    "    ######################## solver ########################\n",
    "    parser.add_argument(\"--optimizer\", type=str, default=\"Adam\", help=\"[SGD, Adam, Adamw]\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-5)\n",
    "    parser.add_argument(\"--bias_lr_factor\", type=float, default=2.)\n",
    "    parser.add_argument(\"--momentum\", type=float, default=0.9)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=4e-5)\n",
    "    parser.add_argument(\"--weight_decay_bias\", type=float, default=0.)\n",
    "    parser.add_argument(\"--alpha\", type=float, default=0.9)\n",
    "    parser.add_argument(\"--beta\", type=float, default=0.999)\n",
    "    \n",
    "    ######################## scheduler ########################\n",
    "    parser.add_argument(\"--num_epoch\", type=int, default=60)\n",
    "    parser.add_argument(\"--milestones\", type=int, nargs='+', default=(20, 50))\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--warmup_factor\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--warmup_epochs\", type=int, default=5)\n",
    "    parser.add_argument(\"--warmup_method\", type=str, default=\"linear\")\n",
    "    parser.add_argument(\"--lrscheduler\", type=str, default=\"cosine\")\n",
    "    parser.add_argument(\"--target_lr\", type=float, default=0)\n",
    "    parser.add_argument(\"--power\", type=float, default=0.9)\n",
    "\n",
    "    ######################## dataset ########################\n",
    "    parser.add_argument(\"--dataset_name\", default=\"CUHK-PEDES\", help=\"[CUHK-PEDES, ICFG-PEDES, RSTPReid]\")\n",
    "    parser.add_argument(\"--sampler\", default=\"random\", help=\"choose sampler from [idtentity, random]\")\n",
    "    parser.add_argument(\"--num_instance\", type=int, default=4)\n",
    "    parser.add_argument(\"--root_dir\", default=\"./data\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--test_batch_size\", type=int, default=512)\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=8)\n",
    "    parser.add_argument(\"--test\", dest='training', default=True, action='store_false')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64639e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_temp_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d13a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=[\n",
    "    \"--name\",\"irra\",\n",
    "    \"--img_aug\",\"--MLM\",\n",
    "    \"--batch_size\",\"16\",\n",
    "    \"--loss_names\",\"itc\",\n",
    "    \"--dataset_name\",\"AGTBPR-a\",\n",
    "    \"--root_dir\",r\"F:\\Datasets\\AG-ReID.v1\",\n",
    "    \"--num_epoch\",\"60\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c495382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904d606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_img_loader, val_txt_loader, num_classes = build_dataloader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a91ff2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8154"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c240e0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " 0,\n",
       " 'F:\\\\Datasets\\\\AG-ReID.v1\\\\AG-ReID\\\\bounding_box_train\\\\P0001T04041A0C0F121.jpg',\n",
       " 'The pedestrian in the image appears to be a male with long hair, wearing a dark-colored hoodie with some text on it. He is also wearing blue jeans and white shoes. He seems to be carrying a white bag or purse in his right hand.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2041dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.build import __factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36149d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import mat4py\n",
    "import pandas as pd\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import json\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cad395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'AG-ReID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c471ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Datasets\\\\AG-ReID.v1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ace94332",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = osp.join(args.root_dir, dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a00c8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = osp.join(dataset_dir, 'bounding_box_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a9ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dir = osp.join(dataset_dir, 'query_all_c0')\n",
    "gallery_dir = osp.join(dataset_dir, 'bounding_box_test_all_c3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a02de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(dataset_dir,\"agtbpr_text.json\"),\"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "text_captions = {list(d.keys())[0]:list(d.values())[0] for d in data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdcc3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_range = [0] # 0 means the pic is getted by Aerials; 3 means Cameras.\n",
    "\n",
    "pid_list = []\n",
    "pid_container = set()    \n",
    "image_id = 0\n",
    "dataset = []\n",
    "image_pids = []\n",
    "image_paths = []\n",
    "caption_pids = []\n",
    "captions = []\n",
    "camera_ids = []\n",
    "gnd_img_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "548da104",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "229aae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_train:\n",
    "    dir_path = train_dir\n",
    "else:\n",
    "    dir_path = [query_dir,gallery_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fcf7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_train:\n",
    "    img_paths = glob.glob(osp.join(dir_path, '*.jpg'))\n",
    "else:\n",
    "    img_paths = glob.glob(osp.join(dir_path[0], '*.jpg')) + glob.glob(osp.join(dir_path[1], '*.jpg'))\n",
    "\n",
    "pattern_pid = re.compile(r'P([-\\d]+)T([-\\d]+)A([-\\d]+)')\n",
    "pattern_camid = re.compile(r'C([-\\d]+)F([-\\d]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b057434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerange pids\n",
    "for img_path in img_paths:\n",
    "    fname = osp.split(img_path)[-1]\n",
    "    pid_part1, pid_part2, pid_part3 = pattern_pid.search(fname).groups()\n",
    "    pid = int(pid_part1 + pid_part2 + pid_part3)\n",
    "    pid_list.append(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36b183d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Aerial-camera pair\n",
    "pid_set = set(pid_list)\n",
    "pid_key = {pid:key for key,pid in enumerate(pid_set)}\n",
    "pid_dict = {key:[] for key in range(len(pid_key))}\n",
    "pid_dict_ptr = {key:0 for key in range(len(pid_key))}\n",
    "for img_path in img_paths:\n",
    "    fname = osp.split(img_path)[-1]\n",
    "    pid_part1, pid_part2, pid_part3 = pattern_pid.search(fname).groups()\n",
    "    pid = int(pid_part1 + pid_part2 + pid_part3)\n",
    "    pid = pid_key[pid]\n",
    "    camid, frameid = pattern_camid.search(fname).groups()\n",
    "    camid = int(camid)\n",
    "    # purn the Camera images\n",
    "    if camid not in cid_range:\n",
    "        pid_dict[pid].append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c65838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "for img_path in img_paths:\n",
    "    fname = osp.split(img_path)[-1]\n",
    "    camid, frameid = pattern_camid.search(fname).groups()\n",
    "    camid = int(camid)\n",
    "    if is_train and camid not in cid_range:\n",
    "        continue\n",
    "\n",
    "    pid_part1, pid_part2, pid_part3 = pattern_pid.search(fname).groups()\n",
    "    pid = int(pid_part1 + pid_part2 + pid_part3)\n",
    "    pid = pid_key[pid]\n",
    "\n",
    "    pid_container.add(pid)\n",
    "\n",
    "    dir_path_tmp, fname_path_tmp = osp.split(img_path)\n",
    "    fname_path_tmp = osp.splitext(fname_path_tmp)[0]\n",
    "    _, dir_path_tmp = osp.split(dir_path_tmp)\n",
    "    key = dir_path_tmp+\"_\"+fname_path_tmp\n",
    "\n",
    "    gnd_img_name = pid_dict[pid][pid_dict_ptr[pid]]\n",
    "    pid_dict_ptr[pid] = (pid_dict_ptr[pid]+1) % len(pid_dict[pid])\n",
    "    if is_train:\n",
    "        dataset.append((pid, image_id, img_path, gnd_img_name, text_captions[key]))\n",
    "        image_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8e546e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43m__factory\u001b[49m\u001b[43m[\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Share\\jupyterDir\\IRRA\\datasets\\agtbpr.py:48\u001b[0m, in \u001b[0;36mAG_ReID.__init__\u001b[1;34m(self, root, verbose, name, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_before_run()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_id_container \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dir, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, camera\u001b[38;5;241m=\u001b[39mcamera)\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_id_container \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcamera\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_id_container \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgallery_dir, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, camera\u001b[38;5;241m=\u001b[39mcamera)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32mE:\\Share\\jupyterDir\\IRRA\\datasets\\agtbpr.py:144\u001b[0m, in \u001b[0;36mAG_ReID._process_dir\u001b[1;34m(self, dir_path, is_train, camera)\u001b[0m\n\u001b[0;32m    141\u001b[0m _, dir_path_tmp \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39msplit(dir_path_tmp)\n\u001b[0;32m    142\u001b[0m key \u001b[38;5;241m=\u001b[39m dir_path_tmp\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfname_path_tmp\n\u001b[1;32m--> 144\u001b[0m gnd_img_name \u001b[38;5;241m=\u001b[39m \u001b[43mpid_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid_dict_ptr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    145\u001b[0m pid_dict_ptr[pid] \u001b[38;5;241m=\u001b[39m (pid_dict_ptr[pid]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(pid_dict[pid])\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_train:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dataset = __factory[args.dataset_name](root=args.root_dir,name = args.dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "114c7705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " 0,\n",
       " 'F:\\\\Datasets\\\\AG-ReID.v1\\\\AG-ReID\\\\bounding_box_train\\\\P0001T04041A0C0F121.jpg',\n",
       " 'The pedestrian in the image appears to be a male with long hair, wearing a dark-colored hoodie with some text on it. He is also wearing blue jeans and white shoes. He seems to be carrying a white bag or purse in his right hand.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df735e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_dict = {key:[] for key in list(set([i[0] for i in dataset.train]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "470e1471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [],\n",
       " 1: [],\n",
       " 2: [],\n",
       " 3: [],\n",
       " 4: [],\n",
       " 5: [],\n",
       " 6: [],\n",
       " 7: [],\n",
       " 8: [],\n",
       " 9: [],\n",
       " 10: [],\n",
       " 11: [],\n",
       " 12: [],\n",
       " 13: [],\n",
       " 14: [],\n",
       " 15: [],\n",
       " 16: [],\n",
       " 17: [],\n",
       " 18: [],\n",
       " 19: [],\n",
       " 20: [],\n",
       " 21: [],\n",
       " 22: [],\n",
       " 23: [],\n",
       " 24: [],\n",
       " 25: [],\n",
       " 26: [],\n",
       " 27: [],\n",
       " 28: [],\n",
       " 29: [],\n",
       " 30: [],\n",
       " 31: [],\n",
       " 32: [],\n",
       " 33: [],\n",
       " 34: [],\n",
       " 35: [],\n",
       " 36: [],\n",
       " 37: [],\n",
       " 38: [],\n",
       " 39: [],\n",
       " 40: [],\n",
       " 41: [],\n",
       " 42: [],\n",
       " 43: [],\n",
       " 44: [],\n",
       " 45: [],\n",
       " 46: [],\n",
       " 47: [],\n",
       " 48: [],\n",
       " 49: [],\n",
       " 50: [],\n",
       " 51: [],\n",
       " 52: [],\n",
       " 53: [],\n",
       " 54: [],\n",
       " 55: [],\n",
       " 56: [],\n",
       " 57: [],\n",
       " 58: [],\n",
       " 59: [],\n",
       " 60: [],\n",
       " 61: [],\n",
       " 62: [],\n",
       " 63: [],\n",
       " 64: [],\n",
       " 65: [],\n",
       " 66: [],\n",
       " 67: [],\n",
       " 68: [],\n",
       " 69: [],\n",
       " 70: [],\n",
       " 71: [],\n",
       " 72: [],\n",
       " 73: [],\n",
       " 74: [],\n",
       " 75: [],\n",
       " 76: [],\n",
       " 77: [],\n",
       " 78: [],\n",
       " 79: [],\n",
       " 80: [],\n",
       " 81: [],\n",
       " 82: [],\n",
       " 83: [],\n",
       " 84: [],\n",
       " 85: [],\n",
       " 86: [],\n",
       " 87: [],\n",
       " 88: [],\n",
       " 89: [],\n",
       " 90: [],\n",
       " 91: [],\n",
       " 92: [],\n",
       " 93: [],\n",
       " 94: [],\n",
       " 95: [],\n",
       " 96: [],\n",
       " 97: [],\n",
       " 98: [],\n",
       " 99: [],\n",
       " 100: [],\n",
       " 101: [],\n",
       " 102: [],\n",
       " 103: [],\n",
       " 104: [],\n",
       " 105: [],\n",
       " 106: [],\n",
       " 107: [],\n",
       " 108: [],\n",
       " 109: [],\n",
       " 110: [],\n",
       " 111: [],\n",
       " 112: [],\n",
       " 113: [],\n",
       " 114: [],\n",
       " 115: [],\n",
       " 116: [],\n",
       " 117: [],\n",
       " 118: [],\n",
       " 119: [],\n",
       " 120: [],\n",
       " 121: [],\n",
       " 122: [],\n",
       " 123: [],\n",
       " 124: [],\n",
       " 125: [],\n",
       " 126: [],\n",
       " 127: [],\n",
       " 128: [],\n",
       " 129: [],\n",
       " 130: [],\n",
       " 131: [],\n",
       " 132: [],\n",
       " 133: [],\n",
       " 134: [],\n",
       " 135: [],\n",
       " 136: [],\n",
       " 137: [],\n",
       " 138: [],\n",
       " 139: [],\n",
       " 140: [],\n",
       " 141: [],\n",
       " 142: [],\n",
       " 143: [],\n",
       " 144: [],\n",
       " 145: [],\n",
       " 146: [],\n",
       " 147: [],\n",
       " 148: [],\n",
       " 149: [],\n",
       " 150: [],\n",
       " 151: [],\n",
       " 152: [],\n",
       " 153: [],\n",
       " 154: [],\n",
       " 155: [],\n",
       " 156: [],\n",
       " 157: [],\n",
       " 158: [],\n",
       " 159: [],\n",
       " 160: [],\n",
       " 161: [],\n",
       " 162: [],\n",
       " 163: [],\n",
       " 164: [],\n",
       " 165: [],\n",
       " 166: [],\n",
       " 167: [],\n",
       " 168: [],\n",
       " 169: [],\n",
       " 170: [],\n",
       " 171: [],\n",
       " 172: [],\n",
       " 173: [],\n",
       " 174: [],\n",
       " 175: [],\n",
       " 176: [],\n",
       " 177: [],\n",
       " 178: [],\n",
       " 179: [],\n",
       " 180: [],\n",
       " 181: [],\n",
       " 182: [],\n",
       " 183: [],\n",
       " 184: [],\n",
       " 185: [],\n",
       " 186: [],\n",
       " 187: [],\n",
       " 188: [],\n",
       " 189: [],\n",
       " 190: [],\n",
       " 191: [],\n",
       " 192: [],\n",
       " 193: [],\n",
       " 194: [],\n",
       " 195: [],\n",
       " 196: [],\n",
       " 197: [],\n",
       " 198: []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in dataset.train:\n",
    "    pid_dict[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6d2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
